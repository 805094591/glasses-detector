{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glasses Detector Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This simply installs the minimum required **Python** version<sup>1</sup>  (`3.12`) and the latest **PyTorch** version (_Nightly_ for compatibility). It may take several minutes to execute the cell because installing **PyTorch** generally takes a while.\n",
    "\n",
    "> **Tip**: If you want, you can change the environment type before running the notebook to support GPU acceleration: `Runtime` $\\to$ `Change runtime type`.\n",
    "\n",
    "<sub>[1] Please note that python script cells cannot be executed directly because _Colab_ kernel version cannot be set to **3.12** at runtime - for this reason, python scripts are wrapped in strings which are then used as arguments when calling `python 3.12` not through kernel. When _Colab_ supports **Python 3.12** or newer, all these complications can be removed.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update -qq -y && sudo apt-get install python3.12 &> /dev/null\n",
    "!sudo update-alternatives --quiet --install /usr/bin/python3 python3 /usr/bin/python3.12 1\n",
    "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.12 &> /dev/null\n",
    "!pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu121 &> /dev/null\n",
    "!pip install ipython pyyaml glasses-detector &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the demo images form the original [GitHub repository](https://github.com/mantasu/glasses-detector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/demo\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/0.jpg -O data/demo/0.jpg\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/1.jpg -O data/demo/1.jpg\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/2.jpg -O data/demo/2.jpg\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/3.jpg -O data/demo/3.jpg\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/4.jpg -O data/demo/4.jpg\n",
    "!wget -q https://raw.githubusercontent.com/mantasu/glasses-detector/main/data/demo/5.jpg -O data/demo/5.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just imports the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# TODO: uncomment when Colab supports Python 3.12\n",
    "# from glasses_detector import GlassesClassifier, GlassesDetector, GlassesSegmenter\n",
    "\n",
    "# TODO: remove when Colab supports Python 3.12\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a utility function to display images from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_in_row(directory, padding=10, sort=False):\n",
    "    # Load all images in the directory\n",
    "    files = sorted(os.listdir(directory)) if sort else os.listdir(directory)\n",
    "    images = [Image.open(os.path.join(directory, img)) for img in files]\n",
    "\n",
    "    # Create a new image with enough width to hold all images and padding\n",
    "    total_width = sum(img.width for img in images) + padding * (len(images) - 1)\n",
    "    max_height = max(img.height for img in images)\n",
    "    new_img = Image.new(\"RGB\", (total_width, max_height))\n",
    "\n",
    "    # Paste images into new image with padding\n",
    "    x = 0\n",
    "    for img in images:\n",
    "        new_img.paste(img, (x, 0))\n",
    "        x += img.width + padding\n",
    "\n",
    "    # Display collage\n",
    "    display(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first run the simplest prediction to see if the person is wearing glasses in `demo/0.jpg`. By default, if we don't specify the task `kind`, it will default to `anyglasses` for _classification_. Default `--format` for classification is `str`, meaning _\"present\"_ will be output for positive predictions and _\"absent\"_ for negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector --input data/demo/0.jpg --task classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run predict if _sunglasses_ are present in every image under `demo/`. In this example, let's choose to save to a single `csv` file and encode predictions as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector -i data/demo -o is_sunglasses.csv --format int --task classification:sunglasses\n",
    "!cat is_sunglasses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform the same prediction considering _anyglasses_ on `demo/1.jpg`. This cell simply shows how to use `process_file` with some _format_ examples. Note that it is also possible to specify `output_path`, specify a list of paths for `input_path`, or, if you only need to return the predictions without showing/saving the results, `predict` method could be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_SINGLE = r\"\"\"\n",
    "from glasses_detector import GlassesClassifier\n",
    "\n",
    "# Load the model for anyglasses classification\n",
    "cls_anyglasses = GlassesClassifier(kind='anyglasses')\n",
    "\n",
    "def my_format(img, pred):\n",
    "    # Define a custom format function (custom label and draw on image)\n",
    "    label = 'Wears glasses' if (pred > 0).item() else 'Does not wear'\n",
    "    return GlassesClassifier.draw_label(img, label)\n",
    "\n",
    "# Process the image with various formats (disable the return values with _)\n",
    "_ = cls_anyglasses.process_file('data/demo/1.jpg', show=True, format='logit')\n",
    "_ = cls_anyglasses.process_file('data/demo/1.jpg', show=True, format={True: 'yes', False: -1})\n",
    "_ = cls_anyglasses.process_file('data/demo/1.jpg', show=True, format=my_format)\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$CLASSIFICATION_SINGLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell shows how to use `process_dir` to save the predictions for each image into a single file and a directory of multiple files (one for each prediction). Note how `cls_sunglasses` can also be just called directly to confirm the presence of _sunglasses_ in `[0.jpg, 3.jpg]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_MULTI = r\"\"\"\n",
    "import json\n",
    "from glasses_detector import GlassesClassifier\n",
    "\n",
    "# Load the model for sunglasses classification\n",
    "cls_sunglasses = GlassesClassifier(kind='sunglasses')\n",
    "\n",
    "# Process a directory of images and save the results to a json file as well as to a directory as images\n",
    "cls_sunglasses.process_dir('data/demo', 'is_sunglasses.json', format='proba', batch_size=3, pbar=False)\n",
    "cls_sunglasses.process_dir('data/demo', 'is_sunglasses', format='img', batch_size=6, pbar=False)\n",
    "\n",
    "# Confirm '0.jpg' and '3.jpg' are indeed sunglasses, print predictions on the whole dir\n",
    "print('[0.jpg, 3.jpg]:', cls_sunglasses(image=['data/demo/0.jpg', 'data/demo/3.jpg']))\n",
    "print(json.load(open('is_sunglasses.json')))\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$CLASSIFICATION_MULTI\"\n",
    "display_images_in_row(\"is_sunglasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an example of a very simple eye area detection on an image with no worn glasses (`demo/2.jpg`) - the bounding box is printed to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector --input data/demo/2.jpg --format str --task detection:eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is just the processing of the whole `demo/` directory where the glasses bounding box predictions are saved as separate `.txt` files (one for each image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector --input data/demo --output glasses_bboxes -f int -e .txt --task detection:worn\n",
    "!for file in glasses_bboxes/*.txt; do head -n 1 \"$file\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell simply repeats the same eye-area prediction as before, except it shows the actual image with the drawn bbox (because now _IPython_ environment is available instead of a pure terminal). Notice how the `GlassesDetector` instance can be simply called directly to perform the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_SINGLE = r\"\"\"\n",
    "from glasses_detector import GlassesDetector\n",
    "\n",
    "# Load the model for eyes detection\n",
    "det_eyes = GlassesDetector(kind='eyes')\n",
    "# det_eyes('data/demo/2.jpg') # default format is 'img'\n",
    "det_eyes('data/demo/2.jpg').save('eyes_bbox.jpg')\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$DETECTION_SINGLE\"\n",
    "display(Image.open(\"eyes_bbox.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment more with different ways multiple files can be processed, different output file formats and different prediction type formats. For bounding boxes, it is generally more preferable to save the results to a single file but saving each prediction to a separate file is also possible as shown before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_MULTI = r\"\"\"\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glasses_detector import GlassesDetector\n",
    "\n",
    "# Initialize glasses detection model\n",
    "det_worn = GlassesDetector(kind='worn')\n",
    "\n",
    "# Process the images in various ways with various outputs and formats\n",
    "det_worn.process_file('data/demo/2.jpg', 'eyes_det.txt', show=False, format='str')\n",
    "det_worn.process_file(['data/demo/0.jpg', 'data/demo/3.jpg'], 'sung_det.yaml', format='float')\n",
    "det_worn.process_dir('data/demo', 'demo_det.pkl', format='bool', batch_size=2, pbar='Predicting bboxes')\n",
    "\n",
    "# Show contents of the saved files\n",
    "print(open('eyes_det.txt').read())\n",
    "print(yaml.safe_load(open('sung_det.yaml')))\n",
    "print(np.stack(list(pickle.load(open('demo_det.pkl', 'rb')).values())).shape)\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$DETECTION_MULTI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask prediction provides information about every pixel, thus it is best to save the mask as a grayscale image or a compressed object, such as `.pkl`, `.dat` or `.npz` as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector -i data/demo/0.jpg -o frames_mask.npz -t segmentation:frames -s small\n",
    "!python -c \"import numpy as np; print(np.load('frames_mask.npz')['arr_0'].shape)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to previous examples, this one just shows how to process a directory of images: here, their _full_ glasses masks are saved as `.png` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glasses-detector -i data/demo -o full_masks_pure -f mask -e .png -t segmentation:full -s medium -b 6 # TODO: change medium to large\n",
    "!ls full_masks_pure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a simple frames segmentation again and show both the regular mask and the inverted one. Notice again, how single image prediction could be simply performed by calling the segmenter instance (or its `predict` method) since there is no need to save any output, but, of course, it is also possible to still call `process_file` without specifying `output_path` and get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTATION_SINGLE = r\"\"\"\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from glasses_detector import GlassesSegmenter\n",
    "\n",
    "# Initialize frames segmentation model of size small\n",
    "seg_frames = GlassesSegmenter(kind='frames', size='small')\n",
    "\n",
    "# Process '0.jpg' to generate glasses frames mask (inverted and original)\n",
    "inverted_mask = seg_frames('data/demo/1.jpg', format={True: 0, False: 255})\n",
    "inverted_mask = Image.fromarray(inverted_mask.numpy(force=True).astype(np.uint8))\n",
    "original_mask = seg_frames.process_file('data/demo/1.jpg', format='mask', show=False)\n",
    "\n",
    "# Show both masks (TODO: change back to .show())\n",
    "# inverted_mask.show()\n",
    "# original_mask.show()\n",
    "inverted_mask.save('inverted_mask.png')\n",
    "original_mask.save('original_mask.png')\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$SEGMENTATION_SINGLE\"\n",
    "display(Image.open(\"inverted_mask.png\"))\n",
    "display(Image.open(\"original_mask.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is just a further example of different output possibilities when processing a directory of image files. In this case, if we specify all the predictions to be saved to a single file, some file formats, such as `.csv` or `.txt` will automatically flatten the `2D` mask to fit into a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTATION_MULTI = r\"\"\"\n",
    "import numpy as np\n",
    "from glasses_detector import GlassesSegmenter\n",
    "\n",
    "# Initialize full segmentation model of size large\n",
    "seg_full = GlassesSegmenter(kind='full', size='medium') # TODO: change medium to large\n",
    "\n",
    "# Process the directory of images and save the results in various ways\n",
    "seg_full.process_dir('data/demo', 'full_masks_over', format='img', batch_size=6, pbar=False)\n",
    "seg_full.process_dir('data/demo', 'full_masks.npy', format='mask', batch_size=6, pbar=False)\n",
    "seg_full.process_dir('data/demo', 'full_masks.csv', format='proba', batch_size=6, pbar=False)\n",
    "\n",
    "# Display the generated masks (and the one from CLI)\n",
    "# display_images_in_row('full_masks_pure', sort=True)\n",
    "# display_images_in_row('full_masks_over', sort=True)\n",
    "print(np.load('full_masks.npy').shape)\n",
    "print(*[','.join(row) + ',...' for row in np.loadtxt('full_masks.csv', delimiter=',', dtype=str)[:, :5]], sep='\\n')\n",
    "\"\"\"\n",
    "\n",
    "!python -c \"$SEGMENTATION_MULTI\"\n",
    "display_images_in_row(\"full_masks_pure\", sort=True)\n",
    "display_images_in_row(\"full_masks_over\", sort=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glasses-detector-312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
